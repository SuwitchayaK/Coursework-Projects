{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhPhYZpCG8St"
   },
   "source": [
    "# **Part IIB: Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NojpM1CdHWCz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o2PIvOzJHiOE"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"MLF_GP1_CreditScore.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M037dGtoHIK9"
   },
   "source": [
    "# **Section IIIA: Investment Grade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "R2TcOH39HlpP"
   },
   "outputs": [],
   "source": [
    "#Separate features and target variables for linear regression and logistic regression\n",
    "X = data.iloc[:, : -2] #exclude target variables from the feature variables\n",
    "y_inv = data.iloc[:, -2] #Select second-last column as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0wv9n4eeH1Na"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Split train and test sets\n",
    "X_train_inv, X_test_inv, y_train_inv, y_test_inv = train_test_split(X, y_inv, test_size=0.2, random_state=511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EApHC_eFHPnj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Gf6m-HXINwY",
    "outputId": "5f093aa5-3c60-40fb-df19-a0b6d33ebde0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 6s 4ms/step - loss: 1.1694 - accuracy: 0.6846\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0437 - accuracy: 0.7074\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7624 - accuracy: 0.7368\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0187 - accuracy: 0.7449\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9357 - accuracy: 0.7419\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7502 - accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.7507\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.7522\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.7471\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.7603\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.7640\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.7515\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.7529\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7544\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.7610\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7566\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.7603\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.7684\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.7618\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7654\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7603\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7618\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7684\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7669\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7750\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7853\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7684\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7735\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7588\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7743\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7706\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7699\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7713\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7757\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7809\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7794\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7772\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7809\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7890\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7824\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7846\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4789 - accuracy: 0.7875\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7912\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.7838\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7875\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7912\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7934\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7956\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7772\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7949\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7926\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7882\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7890\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7956\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7971\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7912\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7934\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7912\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7875\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7985\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7985\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.8000\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7934\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7971\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7993\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8059\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7985\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7963\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8088\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8103\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8110\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8029\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8140\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8162\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8096\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8110\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8118\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8015\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8228\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8074\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8265\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8154\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8066\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.8081\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8206\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8103\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8176\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8118\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8176\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8279\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8059\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8279\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8066\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8309\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8066\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8154\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8287\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8316\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8375\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78484254f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Neural Networks\n",
    "model1 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(26,)),\n",
    "    Dropout(0.2), #Use dropout feature to prevent overfitting\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model1.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy']) #The target is binary, so I will use crossentropy instead of mse\n",
    "model1.fit(X_train_inv, y_train_inv, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wVStpmsKB7T",
    "outputId": "2d9f4253-7bee-46c8-9898-507e139c3bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8235\n",
      "[0.438455730676651, 0.8235294222831726]\n"
     ]
    }
   ],
   "source": [
    "print(model1.evaluate(X_test_inv, y_test_inv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xbo_D5NWeHx"
   },
   "source": [
    "The accuracy to predict whether firm is investment grade is 82.35%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqSVaQDmYRzj"
   },
   "source": [
    "# **Section IIIB: Credit Ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "oL8-Xtv0WqRw"
   },
   "outputs": [],
   "source": [
    "#Select last column as target variable\n",
    "y_rating = data.iloc[:, -1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJ4xIfBCZx91",
    "outputId": "c6a2ae9a-6d0f-4fca-bf8a-7e5326690db9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#Rating is categorical, so I use onehotencoding to convert it to numbers.\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "rating_encoded = encoder.fit_transform(y_rating.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "0qVjnQipZuAe"
   },
   "outputs": [],
   "source": [
    "#Convert encoded array to dataframe\n",
    "y_rating = pd.DataFrame(rating_encoded, columns=encoder.get_feature_names_out(['Rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "9NwsORZXbdex"
   },
   "outputs": [],
   "source": [
    "#Split train and test sets\n",
    "X_train_rating, X_test_rating, y_train_rating, y_test_rating = train_test_split(X, y_rating, test_size=0.2, random_state=511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcTI3kQWalah",
    "outputId": "a372d0fb-ffee-468d-a7d0-395ce8e93a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "136/136 [==============================] - 2s 3ms/step - loss: 3.7463 - accuracy: 0.1206\n",
      "Epoch 2/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.9200 - accuracy: 0.1647\n",
      "Epoch 3/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.6511 - accuracy: 0.1794\n",
      "Epoch 4/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 2.5707 - accuracy: 0.1838\n",
      "Epoch 5/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.5274 - accuracy: 0.1750\n",
      "Epoch 6/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 2.4970 - accuracy: 0.1779\n",
      "Epoch 7/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.4863 - accuracy: 0.2022\n",
      "Epoch 8/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.4237 - accuracy: 0.1926\n",
      "Epoch 9/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 2.4203 - accuracy: 0.2051\n",
      "Epoch 10/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 2.3967 - accuracy: 0.2118\n",
      "Epoch 11/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 2.3379 - accuracy: 0.2184\n",
      "Epoch 12/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 2.3593 - accuracy: 0.2213\n",
      "Epoch 13/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 2.3139 - accuracy: 0.2279\n",
      "Epoch 14/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.2892 - accuracy: 0.2294\n",
      "Epoch 15/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.2692 - accuracy: 0.2412\n",
      "Epoch 16/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.2617 - accuracy: 0.2309\n",
      "Epoch 17/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.2523 - accuracy: 0.2294\n",
      "Epoch 18/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.2329 - accuracy: 0.2316\n",
      "Epoch 19/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.2101 - accuracy: 0.2294\n",
      "Epoch 20/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.2074 - accuracy: 0.2544\n",
      "Epoch 21/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.2053 - accuracy: 0.2471\n",
      "Epoch 22/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.2171 - accuracy: 0.2390\n",
      "Epoch 23/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.1812 - accuracy: 0.2618\n",
      "Epoch 24/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.1753 - accuracy: 0.2603\n",
      "Epoch 25/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.1347 - accuracy: 0.2588\n",
      "Epoch 26/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.1402 - accuracy: 0.2691\n",
      "Epoch 27/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.1640 - accuracy: 0.2765\n",
      "Epoch 28/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.0924 - accuracy: 0.2875\n",
      "Epoch 29/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.0808 - accuracy: 0.2860\n",
      "Epoch 30/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.0777 - accuracy: 0.2919\n",
      "Epoch 31/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.0943 - accuracy: 0.2816\n",
      "Epoch 32/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.0614 - accuracy: 0.3007\n",
      "Epoch 33/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 2.0552 - accuracy: 0.2926\n",
      "Epoch 34/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 2.0639 - accuracy: 0.2853\n",
      "Epoch 35/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 2.0409 - accuracy: 0.3125\n",
      "Epoch 36/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 2.0406 - accuracy: 0.2963\n",
      "Epoch 37/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.0046 - accuracy: 0.3059\n",
      "Epoch 38/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9930 - accuracy: 0.3213\n",
      "Epoch 39/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.1906 - accuracy: 0.3206\n",
      "Epoch 40/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9737 - accuracy: 0.3257\n",
      "Epoch 41/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9606 - accuracy: 0.3331\n",
      "Epoch 42/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 2.0770 - accuracy: 0.3235\n",
      "Epoch 43/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9871 - accuracy: 0.3199\n",
      "Epoch 44/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9413 - accuracy: 0.3176\n",
      "Epoch 45/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9214 - accuracy: 0.3434\n",
      "Epoch 46/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9009 - accuracy: 0.3610\n",
      "Epoch 47/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.8938 - accuracy: 0.3368\n",
      "Epoch 48/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9630 - accuracy: 0.3360\n",
      "Epoch 49/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.9411 - accuracy: 0.3485\n",
      "Epoch 50/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.8642 - accuracy: 0.3419\n",
      "Epoch 51/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.9073 - accuracy: 0.3390\n",
      "Epoch 52/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.9210 - accuracy: 0.3581\n",
      "Epoch 53/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.8599 - accuracy: 0.3522\n",
      "Epoch 54/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.8588 - accuracy: 0.3500\n",
      "Epoch 55/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.8243 - accuracy: 0.3596\n",
      "Epoch 56/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.8422 - accuracy: 0.3684\n",
      "Epoch 57/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 1.8216 - accuracy: 0.3632\n",
      "Epoch 58/100\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 1.8473 - accuracy: 0.3684\n",
      "Epoch 59/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 1.7950 - accuracy: 0.3904\n",
      "Epoch 60/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 1.8110 - accuracy: 0.3809\n",
      "Epoch 61/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.7687 - accuracy: 0.4051\n",
      "Epoch 62/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.7552 - accuracy: 0.3816\n",
      "Epoch 63/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.7717 - accuracy: 0.3941\n",
      "Epoch 64/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.7363 - accuracy: 0.3963\n",
      "Epoch 65/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.7704 - accuracy: 0.4022\n",
      "Epoch 66/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.8300 - accuracy: 0.3956\n",
      "Epoch 67/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.7193 - accuracy: 0.4059\n",
      "Epoch 68/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.7103 - accuracy: 0.4169\n",
      "Epoch 69/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.7368 - accuracy: 0.4147\n",
      "Epoch 70/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.7796 - accuracy: 0.4184\n",
      "Epoch 71/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.6812 - accuracy: 0.4272\n",
      "Epoch 72/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.6664 - accuracy: 0.4235\n",
      "Epoch 73/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.6760 - accuracy: 0.4110\n",
      "Epoch 74/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.6476 - accuracy: 0.4243\n",
      "Epoch 75/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.8201 - accuracy: 0.4228\n",
      "Epoch 76/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.6601 - accuracy: 0.4279\n",
      "Epoch 77/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.6001 - accuracy: 0.4566\n",
      "Epoch 78/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.6005 - accuracy: 0.4463\n",
      "Epoch 79/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.5722 - accuracy: 0.4721\n",
      "Epoch 80/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.5732 - accuracy: 0.4801\n",
      "Epoch 81/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 1.6141 - accuracy: 0.4412\n",
      "Epoch 82/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 1.6113 - accuracy: 0.4581\n",
      "Epoch 83/100\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 1.5720 - accuracy: 0.4603\n",
      "Epoch 84/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.5675 - accuracy: 0.4647\n",
      "Epoch 85/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.5842 - accuracy: 0.4603\n",
      "Epoch 86/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.5701 - accuracy: 0.4654\n",
      "Epoch 87/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.5306 - accuracy: 0.4853\n",
      "Epoch 88/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.5381 - accuracy: 0.4721\n",
      "Epoch 89/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.5255 - accuracy: 0.4868\n",
      "Epoch 90/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.5226 - accuracy: 0.4956\n",
      "Epoch 91/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.5222 - accuracy: 0.4926\n",
      "Epoch 92/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.5430 - accuracy: 0.4904\n",
      "Epoch 93/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.4875 - accuracy: 0.4926\n",
      "Epoch 94/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.4968 - accuracy: 0.4985\n",
      "Epoch 95/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.4924 - accuracy: 0.4897\n",
      "Epoch 96/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.4913 - accuracy: 0.4875\n",
      "Epoch 97/100\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.4307 - accuracy: 0.5110\n",
      "Epoch 98/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.4588 - accuracy: 0.4985\n",
      "Epoch 99/100\n",
      "136/136 [==============================] - 0s 4ms/step - loss: 1.4662 - accuracy: 0.5125\n",
      "Epoch 100/100\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 1.4340 - accuracy: 0.5162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f77941a06a0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Neural Networks\n",
    "model2 = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(26,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='softmax')\n",
    "])\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #The target is categorical, so I adjust loss argument\n",
    "model2.fit(X_train_rating, y_train_rating, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTakq0HLc-C6",
    "outputId": "647fbe97-7427-40d4-ec0f-9d3fd848cd30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 2.4223 - accuracy: 0.3912\n",
      "[2.4222590923309326, 0.3911764621734619]\n"
     ]
    }
   ],
   "source": [
    "print(model2.evaluate(X_test_rating, y_test_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InBFTUqZnp2G"
   },
   "source": [
    "The accuracy predicting credit rating of firm is 39.12%"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
